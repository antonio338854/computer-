import cv2
import av
import mediapipe as mp
import streamlit as st
from streamlit_webrtc import webrtc_streamer, WebRtcMode

# === Configura√ß√£o da P√°gina ===
st.set_page_config(page_title="Tony Hand-Skeletor", page_icon="üñêÔ∏è", layout="centered")

st.title("üñêÔ∏è Detector de M√£os - Tony Skeletor")
st.caption("Rastreamento de 21 pontos biomec√¢nicos em tempo real.")

# === Sidebar ===
with st.sidebar:
    st.header("Configura√ß√µes Neurais")
    confianca = st.slider("Sensibilidade de Detec√ß√£o", 0.1, 1.0, 0.5)
    st.info("Quanto maior a sensibilidade, mais certeza a IA precisa ter para desenhar a m√£o. Se estiver falhando, diminua.")
    st.markdown("---")
    st.markdown("### üëë Tecnologia Google MediaPipe + Tony")

# === Inicializa√ß√£o do MediaPipe ===
mp_drawing = mp.solutions.drawing_utils
mp_drawing_styles = mp.solutions.drawing_styles
mp_hands = mp.solutions.hands

# Inicializa o modelo de m√£os FORA do loop para n√£o travar a mem√≥ria
hands_processor = mp_hands.Hands(
    model_complexity=0,  # 0 √© mais r√°pido (bom para celular), 1 √© mais preciso
    min_detection_confidence=confianca,
    min_tracking_confidence=confianca,
    max_num_hands=2
)

# === Processador de V√≠deo ===
class HandDetector:
    def recv(self, frame):
        # 1. Converte o frame do WebRTC (av) para OpenCV (numpy)
        img = frame.to_ndarray(format="bgr24")
        
        # 2. Converte BGR para RGB (O MediaPipe s√≥ enxerga RGB)
        img.flags.writeable = False # Otimiza√ß√£o de performance
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        
        # 3. A M√°gica: Detecta as m√£os
        results = hands_processor.process(img_rgb)
        
        # 4. Desenha o esqueleto se achar m√£os
        img.flags.writeable = True
        
        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                # Desenha os pontos (juntas) e conex√µes (ossos)
                mp_drawing.draw_landmarks(
                    img,
                    hand_landmarks,
                    mp_hands.HAND_CONNECTIONS,
                    mp_drawing_styles.get_default_hand_landmarks_style(),
                    mp_drawing_styles.get_default_hand_connections_style()
                )
                
        # 5. Retorna o frame desenhado
        return av.VideoFrame.from_ndarray(img, format="bgr24")

# === Interface ===
st.markdown("### üß¨ Ativar Vis√£o Biomec√¢nica")
st.info("Levante as m√£os para a c√¢mera. Funciona melhor com boa ilumina√ß√£o.")

# Streamer WebRTC
webrtc_streamer(
    key="hand-detection",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    video_processor_factory=HandDetector,
    media_stream_constraints={"video": True, "audio": False},
    async_processing=True,
)

st.markdown("---")
st.markdown("**Powered by Python & MediaPipe**")
